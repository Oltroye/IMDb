import pandas as pd
import nltk
import seaborn as sns
import matplotlib.pyplot as plt
from nltk.sentiment import SentimentIntensityAnalyzer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# ðŸ“Œ TÃ©lÃ©charger les ressources NLTK si ce n'est pas dÃ©jÃ  fait
nltk.download('vader_lexicon')
nltk.download('punkt')

# ðŸ“Œ Charger le dataset IMDB
df = pd.read_csv("IMDB Dataset.csv")

# ðŸ“Œ VÃ©rifier les valeurs manquantes
print("\nðŸ” Valeurs manquantes par colonne :")
print(df.isnull().sum())

# ðŸ“Œ Analyser la rÃ©partition des sentiments
print("\nâš–ï¸ RÃ©partition des sentiments :")
print(df['sentiment'].value_counts())

# ðŸ“Œ Ajouter une colonne de longueur des critiques
df['review_length'] = df['review'].apply(len)

# ðŸ“Œ Afficher les statistiques de longueur des critiques
print("\nðŸ“ Statistiques sur la longueur des critiques :")
print(df['review_length'].describe())

# ðŸ“Š **Visualisation des donnÃ©es**
plt.figure(figsize=(12, 5))

# 1ï¸âƒ£ Histogramme des longueurs des critiques
plt.subplot(1, 2, 1)
sns.histplot(df['review_length'], bins=30, kde=True, color='blue')
plt.title("Distribution de la longueur des critiques")
plt.xlabel("Longueur (nombre de caractÃ¨res)")
plt.ylabel("Nombre de critiques")

# 2ï¸âƒ£ Graphique en barres des sentiments
plt.subplot(1, 2, 2)
sns.countplot(x=df['sentiment'], palette=['green', 'red'])
plt.title("RÃ©partition des critiques positives et nÃ©gatives")
plt.xlabel("Sentiment")
plt.ylabel("Nombre de critiques")

plt.tight_layout()
plt.show()

# **Analyse de sentiment avec NLTK VADER**
sia = SentimentIntensityAnalyzer()

# Appliquer VADER sur chaque critique et rÃ©cupÃ©rer le score compound
df['vader_score'] = df['review'].apply(lambda x: sia.polarity_scores(x)['compound'])

# DÃ©terminer la classification des sentiments avec VADER
def classify_sentiment(score):
    if score >= 0.05:
        return 'positive'
    elif score <= -0.05:
        return 'negative'
    else:
        return 'neutral'

df['vader_sentiment'] = df['vader_score'].apply(classify_sentiment)

# Compter les avis neutres, positifs et nÃ©gatifs
sentiment_counts = df['vader_sentiment'].value_counts()
print("\nðŸ“Š RÃ©partition des critiques selon VADER :")
print(sentiment_counts)

# **Visualisation des rÃ©sultats de VADER**
plt.figure(figsize=(6, 4))
sns.countplot(x=df['vader_sentiment'], palette=['green', 'gray', 'red'])
plt.title("RÃ©partition des critiques selon le sentiment VADER")
plt.xlabel("Sentiment")
plt.ylabel("Nombre de critiques")
plt.show()

# **TF-IDF pour vectoriser les critiques**
df['review_cleaned'] = df['review'].str.lower()

vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)
X_vectorized = vectorizer.fit_transform(df['review_cleaned'])

# **SÃ©parer les donnÃ©es en train/test**
X_train, X_test, y_train, y_test = train_test_split(
    X_vectorized, df['sentiment'], test_size=0.2, random_state=42
)

# **EntraÃ®ner un modÃ¨le de classification (rÃ©gression logistique)**
model = LogisticRegression()
model.fit(X_train, y_train)

# **PrÃ©dictions sur les donnÃ©es test**
y_pred = model.predict(X_test)

# **Ã‰valuation du modÃ¨le**
accuracy = accuracy_score(y_test, y_pred)
print(f"\nâœ… PrÃ©cision du modÃ¨le : {accuracy:.2%}")

# **Rapport dÃ©taillÃ© des performances**
print("\nðŸ“Š Rapport de classification :")
print(classification_report(y_test, y_pred))

# **Visualisation des prÃ©dictions**
plt.figure(figsize=(6, 4))
sns.countplot(x=y_pred, palette=['green', 'red'])
plt.title("RÃ©partition des prÃ©dictions du modÃ¨le")
plt.xlabel("Sentiment prÃ©dit")
plt.ylabel("Nombre d'avis")
plt.show()
